<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="stylesheet" href="/assets/css/just-the-docs-default.css"><link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet"><style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li > a, .site-nav > ul.nav-list:first-child > li > ul > li > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li:not(:nth-child(2)) > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li > ul > li a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(2) > ul > li:nth-child(3) > ul > li:nth-child(2) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(2) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(2) > ul > li:nth-child(3) > button svg, .site-nav > ul.nav-list:first-child > li:nth-child(2) > ul > li:nth-child(3) > ul > li:nth-child(2) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(2) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(2) > ul.nav-list > li.nav-list-item:nth-child(3) > ul.nav-list, .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(2) > ul.nav-list > li.nav-list-item:nth-child(3) > ul.nav-list > li.nav-list-item:nth-child(2) > ul.nav-list { display: block; }</style><script src="/assets/js/vendor/lunr.min.js"></script> <script src="/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>Clustering | HS Website</title><meta name="generator" content="Jekyll v4.3.3" /><meta property="og:title" content="Clustering" /><meta property="og:locale" content="en_US" /><meta name="description" content="HS Website" /><meta property="og:description" content="HS Website" /><link rel="canonical" href="http://localhost:4000/docs/CSCI%205622%20-%20ML/models/clustering/" /><meta property="og:url" content="http://localhost:4000/docs/CSCI%205622%20-%20ML/models/clustering/" /><meta property="og:site_name" content="HS Website" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Clustering" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"HS Website","headline":"Clustering","url":"http://localhost:4000/docs/CSCI%205622%20-%20ML/models/clustering/"}</script><body> <a class="skip-to-main" href="#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"><title id="svg-external-link-title">(external link)</title><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-copy" viewBox="0 0 16 16"><title>Copy</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"><title>Copied</title><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"><path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/> </svg> </symbol> </svg><div class="side-bar"><div class="site-header" role="banner"> <a href="/" class="site-title lh-tight"> HS Website </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button></div><nav aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in CSCI 5622 - ML category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/CSCI%205622%20-%20ML/index-CSCI/" class="nav-list-link">CSCI 5622 - ML</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/CSCI%205622%20-%20ML/introduction/" class="nav-list-link">Introduction</a><li class="nav-list-item"><a href="/docs/CSCI%205622%20-%20ML/data_prep/" class="nav-list-link">Data Preparation/EDA</a><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Models/Methods category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="/docs/CSCI%205622%20-%20ML/models/index-models/" class="nav-list-link">Models/Methods</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/CSCI%205622%20-%20ML/models/pca/" class="nav-list-link">Principal Component Analysis <b>(PCA)</b></a><li class="nav-list-item"><a href="/docs/CSCI%205622%20-%20ML/models/clustering/" class="nav-list-link">Clustering</a><li class="nav-list-item"><a href="/docs/CSCI%205622%20-%20ML/models/arm/" class="nav-list-link">Association Rule Mining <b>(ARM)</b></a><li class="nav-list-item"><a href="/docs/CSCI%205622%20-%20ML/models/dt/" class="nav-list-link">Decision Trees <b>(DT)</b></a><li class="nav-list-item"><a href="/docs/CSCI%205622%20-%20ML/models/nb/" class="nav-list-link">Naive Bayes <b>(NB)</b></a><li class="nav-list-item"><a href="/docs/CSCI%205622%20-%20ML/models/svm/" class="nav-list-link">Support Vector Machines <b>(SVM)</b></a><li class="nav-list-item"><a href="/docs/CSCI%205622%20-%20ML/models/regression/" class="nav-list-link">Regression</a></ul><li class="nav-list-item"><a href="/docs/CSCI%205622%20-%20ML/conclusion/" class="nav-list-link">Conclusion</a></ul></ul></nav><footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search" role="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search HS Website" aria-label="Search HS Website" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="https://github.com/hese1175/hese1175.github.io/" class="site-button" target="_blank" rel="noopener noreferrer" > HS Website on GitHub </a></ul></nav></div><div class="main-content-wrap"><nav aria-label="Breadcrumb" class="breadcrumb-nav"><ol class="breadcrumb-nav-list"><li class="breadcrumb-nav-list-item"><a href="/docs/CSCI%205622%20-%20ML/index-CSCI/">CSCI 5622 - ML</a><li class="breadcrumb-nav-list-item"><a href="/docs/CSCI%205622%20-%20ML/models/index-models/">Models/Methods</a><li class="breadcrumb-nav-list-item"><span>Clustering</span></ol></nav><div id="main-content" class="main-content"><main><h1 class="no_toc" id="clustering"> <a href="#clustering" class="anchor-heading" aria-labelledby="clustering"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Clustering</h1><ol id="markdown-toc"><li><a href="#overview" id="markdown-toc-overview">Overview</a><li><a href="#data" id="markdown-toc-data">Data</a><li><a href="#code" id="markdown-toc-code">Code</a><li><a href="#results" id="markdown-toc-results">Results</a><ol><li><a href="#k-means-clustering" id="markdown-toc-k-means-clustering">K-Means Clustering</a><li><a href="#hierarchical-clustering" id="markdown-toc-hierarchical-clustering">Hierarchical Clustering</a><li><a href="#dbscan-clustering" id="markdown-toc-dbscan-clustering">DBSCAN Clustering</a></ol></ol><h2 id="overview"> <a href="#overview" class="anchor-heading" aria-labelledby="overview"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Overview</h2><p>Clustering is an unsupervised machine learning technique used to group similar data points together. The goal of clustering is to identify patterns and structures in the data that are not explicitly labeled. Clustering algorithms partition the data into groups based on the similarity of data points, with the objective of maximizing the intra-cluster similarity and minimizing the inter-cluster similarity.</p><p>Some key concepts in clustering include:</p><ul><li><strong>Centroid</strong>: The center of a cluster, which is calculated as the mean of all data points in the cluster.<li><strong>Distance Metric</strong>: A measure of similarity between data points, which is used to determine which points belong to the same cluster.</ul><p>In this project, clustering will be used to identify materials of wind turbine blades with similar properties. The clustering algorithm will group together items with similar material composition, and performance characteristics. This information can be used to identify important features of materials to consider and will help drop the less important features.</p><p>There are several clustering algorithms available, each with its own strengths and weaknesses. Some common clustering algorithms used in this project include:</p><ul><li><strong>K-Means</strong>: A partitioning algorithm that divides the data into K clusters by iteratively assigning data points to the nearest cluster centroid and updating the centroids based on the mean of the data points in each cluster. <img src="/assets/imgs/clustering/k-means.png" alt="K-Means Clustering" /><li><strong>Hierarchical Clustering</strong>: A hierarchical algorithm that builds a tree of clusters by iteratively merging or splitting clusters based on the similarity of data points. <img src="/assets/imgs/clustering/hierarchical.png" alt="Hierarchical Clustering" /><li><strong>DBSCAN (Density-Based Spatial Clustering of Applications with Noise)</strong>: A density-based algorithm that groups together data points that are closely packed and separates outliers as noise. <img src="/assets/imgs/clustering/dbscan.jpeg" alt="DBSCAN Clustering" /></ul><p>References:<br /> [1]: https://keytodatascience.com/k-means-clustering-algorithm/ <br /> [2]: https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68 <br /> [3]: https://www.geeksforgeeks.org/dbscan-clustering-in-ml-density-based-clustering/</p><h2 id="data"> <a href="#data" class="anchor-heading" aria-labelledby="data"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Data</h2><p>The data is prepped in a similar fashion to the PCA model. Please refer to the PCA page for more information.</p><p>The n_components = 3 is used to reduce the dimensionality of the dataset to 3 principal components.</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>PCA Data n=3 (first 10 rows):
       pc1    pc2    pc3   Resin Type
0   -2.189 -0.355  0.009        Epoxy
1   -2.254 -0.525  0.004        Epoxy
2   -2.139 -0.201  0.014        Epoxy
3   -2.123 -0.092  0.018        Epoxy
4   -2.119 -0.072  0.013        Epoxy
5   -2.194 -0.174  0.014        Epoxy
6   -2.079  0.144  0.022        Epoxy
7   -2.238 -0.220  0.014        Epoxy
8   -2.233 -0.495  0.004        Epoxy
9   -2.238 -0.443 -0.000        Epoxy

Cumulative Explained Variance Ratio: 
[0.42561841 0.66286118 0.82963867]
</code></pre></div></div><p>So the first 3 principal components explain 82.96% of the variance in the data.</p><p>This data will be used to perform all clustering algorithms.</p><h2 id="code"> <a href="#code" class="anchor-heading" aria-labelledby="code"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Code</h2><p>The code is provided in the GitHub repository using the link below:</p><p><a href="/assets/code/clustering.py">Clustering Code</a></p><h2 id="results"> <a href="#results" class="anchor-heading" aria-labelledby="results"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Results</h2><h3 id="k-means-clustering"> <a href="#k-means-clustering" class="anchor-heading" aria-labelledby="k-means-clustering"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> K-Means Clustering</h3><p>The K-Means algorithm was applied to the dataset with n_clusters=[2,3,4]. Here is the plot of the clusters:</p><p><img src="/assets/imgs/clustering/k-means_result.png" alt="K-Means Clustering" /></p><p>The plots show the original data points colored by their true labels and the centroids of the clusters for each value of k. By comparing these plots, you can see how the clustering changes with different values of k.<br /> k=2: This clustering seems to separate the data into two distinct groups, but it might not capture the full complexity of the data.<br /> k=3: This clustering appears to identify three clusters that might better represent the underlying structure of the data.<br /> k=4: This clustering results in four clusters, but it might be overfitting the data, as the clusters seem to fit some outliers.</p><p>In this case, k=3 seems to provide a good balance between capturing the structure of the data and avoiding overfitting.</p><h3 id="hierarchical-clustering"> <a href="#hierarchical-clustering" class="anchor-heading" aria-labelledby="hierarchical-clustering"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Hierarchical Clustering</h3><p>The Hierarchical Clustering algorithm was applied to the dataset. Here is the dendrogram of the clusters:</p><p><img src="/assets/imgs/clustering/hierarchical_results.png" alt="Hierarchical Clustering" /></p><p>The dendrogram shows the hierarchical structure of the clusters, with the data points at the bottom and the clusters at the top. We can see that in this case, the small cluster (orange) is not considered an outlier, but rather a separate cluster. This might be due to the hierarchical nature of the algorithm, which allows for more flexibility in defining clusters. Otherwise, the results match the K-Means clustering with k=3 without the need to specify the number of clusters.</p><h3 id="dbscan-clustering"> <a href="#dbscan-clustering" class="anchor-heading" aria-labelledby="dbscan-clustering"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> DBSCAN Clustering</h3><p>The DBSCAN algorithm was applied to the dataset with eps=0.5 and min_samples=10. Here is the plot of the clusters:</p><p><img src="/assets/imgs/clustering/dbscan_eps05.png" alt="DBSCAN Clustering" /></p><p>The plot shows the original data points colored by their true labels and the clusters identified by DBSCAN. The algorithm seems to identify three main clusters and some outliers. The clusters are well-separated and capture the structure of the data well. The outliers are labeled as noise in black, which is a useful feature of this method.</p><p>DBSCAN was also applied with eps=0.8 and min_samples=10. Here is the plot of the clusters:</p><p><img src="/assets/imgs/clustering/dbscan_eps08.png" alt="DBSCAN Clustering" /></p><p>We still notice three main clusters, but the outliers are now included in the clusters. This might be due to the larger value of eps, which allows for more points to be considered part of the same cluster.</p><p>For this case, DBSCAN with eps=0.5 seems to provide a good balance between capturing the structure of the data and avoiding overfitting.</p><p>To compare the results of the clustering algorithms, we can use metrics such as the silhouette score, which measures the quality of the clusters. The silhouette score ranges from -1 to 1, with higher values indicating better clustering. The silhouette score for each algorithm is as follows:</p><div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>K-means (k=3) Silhouette Score:             0.567
Hierarchical Clustering Silhouette Score:   0.667
DBSCAN Silhouette Score (eps=0.5):          0.532
</code></pre></div></div><p>So, in this case, Hierarchical Clustering seems to provide the best clustering results based on the silhouette score.</p></main><hr><footer><p><a href="#top" id="back-to-top">Back to top</a></p><p class="text-small text-grey-dk-100 mb-0">Copyright &copy; <script>document.write(new Date().getFullYear())</script> <a href="https://github.com/hese1175/hese1175.github.io/">HS Website</a>. All rights reserved.</p><div class="d-flex mt-2"></div></footer></div></div><div class="search-overlay"></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@9.1.6/dist/mermaid.min.js"></script> <script> var config = {} ; mermaid.initialize(config); window.mermaid.init(undefined, document.querySelectorAll('.language-mermaid')); </script>
